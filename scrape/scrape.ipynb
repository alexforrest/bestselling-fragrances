{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import urllib.request as urllib\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from csv import DictWriter\n",
    "\n",
    "\n",
    "wurl = \"https://www.sephora.com/shop/fragrances-for-women\"\n",
    "murl = \"https://www.sephora.com/shop/fragrances-for-men\"\n",
    "burl = \"https://www.sephora.com/best-selling-perfume\"\n",
    "\n",
    "\n",
    "def auto_pagedowns(browser, no_of_pagedowns):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        -selenium browser connection\n",
    "        -number of pg downs\n",
    "    output: pg html\n",
    "    \"\"\"\n",
    "    elem = browser.find_element_by_tag_name(\"a\")\n",
    "    while no_of_pagedowns:\n",
    "        elem.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(0.1)\n",
    "        no_of_pagedowns-=1\n",
    "    html = browser.page_source\n",
    "    return html\n",
    "\n",
    "def close_popup(browser):\n",
    "    try:\n",
    "        browser.find_element_by_xpath(\"//*/button[@aria-label='Close']\").click()\n",
    "    except:\n",
    "        #close bestseller pop-up\n",
    "        browser.find_element_by_xpath(\"//*/button[@class='Modal-close ng-scope']\").click()\n",
    "    \n",
    "    \n",
    "\n",
    "def run_automations(url, pages=20, no_of_pagedowns=6):\n",
    "    \"\"\"\n",
    "    input: url from sephora.com/shop/fragrances...\n",
    "    runs automation to close pop-up, run page down, and navigate to next pg actions\n",
    "    output: list of urls for each fragrance by page\n",
    "    \"\"\"\n",
    "    url_list = []\n",
    "    \n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(url)\n",
    "    time.sleep(.5)\n",
    "    \n",
    "    close_popup(browser)\n",
    "    time.sleep(.2)\n",
    "  \n",
    "    for page in range(pages):\n",
    "        #click on 'next button' to navigate to next pg\n",
    "        if page == 1:\n",
    "            browser.find_element_by_class_name('css-1be47h1').click()\n",
    "        elif page != 0:\n",
    "            browser.find_elements_by_class_name('css-1be47h1')[1].click()\n",
    "        #page down \n",
    "        html = auto_pagedowns(browser, no_of_pagedowns)\n",
    "        url_list.append(get_detail_url(html))\n",
    "        \n",
    "    #handels case where there are no other pages to navigate to    \n",
    "    if pages == 0:\n",
    "        html = auto_pagedowns(browser, no_of_pagedowns)\n",
    "        url_list.append(get_detail_url(html, True))\n",
    "        \n",
    "    return url_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_detail_url(html, page_zero=False):\n",
    "    \"\"\"\n",
    "    input: html from sephora.com/shop/fragrances...\n",
    "    output: url for detail page for each fragrance\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    perfume_divs = soup.find_all('div', attrs= {'class': 'css-12egk0t'})\n",
    "    \n",
    "    #handles bestsellers html format\n",
    "    if page_zero == True:\n",
    "        perfume_divs = soup.find_all('a', attrs= {'class': 'u-size1of4'})\n",
    "    num_of_perfumes = len(perfume_divs)\n",
    "    \n",
    "    urls = []\n",
    "    \n",
    "    for i, div in enumerate(perfume_divs):\n",
    "        try:\n",
    "            urls.append(div.find('a')['href'])\n",
    "        \n",
    "        except:\n",
    "            urls.append(div['href'])\n",
    "    return urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ONLY RUN ONCE\"\"\"\n",
    "\"\"\"script to write csv files for fragrance urls\"\"\"\n",
    "\n",
    "#get urls for fragrance products\n",
    "wurls_list = run_automations(wurl)\n",
    "murls_list = run_automations(murl, pages=6)\n",
    "burl_list = run_automations(burl, pages = 0, no_of_pagedowns=22)\n",
    "\n",
    "#flatten list of lists\n",
    "wurls = [urls.split(' ')[0] for ulist in wurls_list for urls in ulist]\n",
    "murls = [urls.split(' ')[0] for ulist in murls_list for urls in ulist]\n",
    "burls = [urls.split(' ')[0] for ulist in burl_list for urls in ulist]\n",
    "\n",
    "import csv\n",
    "\n",
    "def url_csv(urls, csvfile):\n",
    "    \"\"\"\n",
    "    write urls to csv\n",
    "    inputs: \n",
    "    list of urls\n",
    "    file path\n",
    "    \"\"\"\n",
    "    with open(csvfile, \"w\") as f:\n",
    "        writer = csv.writer(f, delimiter = \",\")\n",
    "        for url in urls:\n",
    "            writer.writerow([url])    \n",
    "\n",
    "women_csvfile = \"women_fragrance_urls.csv\"\n",
    "men_csvfile = \"men_fragrance_urls.csv\"\n",
    "bestsellers_csvfile = \"bestsellers_urls.csv\"\n",
    "\n",
    "url_csv(murls, men_csvfile )\n",
    "url_csv(wurls, women_csvfile)\n",
    "url_csv(burls, bestsellers_csvfile )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_opener():\n",
    "    opener = urllib.build_opener()\n",
    "    opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "    urllib.install_opener(opener)\n",
    "    \n",
    "\n",
    "def write_image(url, filepath):\n",
    "    \"\"\"takes url and filepath to write image to new file\"\"\"\n",
    "    build_opener()\n",
    "    urllib.urlretrieve(url, filepath)\n",
    "\n",
    "write_image(url, 'images/image2.jpg')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brand_perfume(soup):\n",
    "    try:\n",
    "        header = soup.find('h1', attrs = {'class': 'css-g397qt'})\n",
    "    except:\n",
    "        return None\n",
    "    return [inner.contents[0] for inner in header.find_all('span')]\n",
    "\n",
    "def get_item_no(soup):\n",
    "    item = soup.find('div', attrs = {'class': 'css-altys'})\n",
    "    item_no = list(item.strings)\n",
    "    return(item_no)\n",
    "\n",
    "def get_user_feedback(soup):\n",
    "    try:\n",
    "        feedback = soup.find('div', attrs = {'class': 'css-12ua0v8'})\n",
    "    except:\n",
    "        return None\n",
    "    feedback_data = [list(inner.strings) for inner in feedback.find_all('span')][:2]\n",
    "    return feedback_data\n",
    "\n",
    "def get_price(soup):\n",
    "    try:\n",
    "        price = soup.find('div', attrs = {'class': 'css-n8yjg7'}).contents\n",
    "    except:\n",
    "        return None\n",
    "    return price\n",
    "\n",
    "def get_oz(soup):\n",
    "    try:\n",
    "        ozs = soup.find('span', attrs = {'class': 'css-fp7pgu'}).contents\n",
    "    except:\n",
    "        return None\n",
    "    return ozs\n",
    "\n",
    "def get_options(soup):\n",
    "    try:\n",
    "        options = list(soup.find('div', attrs = {'class': 'css-1h02kfs'}).strings)\n",
    "    except:\n",
    "        return None\n",
    "    return options\n",
    "\n",
    "def get_fragrance_info(soup):\n",
    "    try:\n",
    "        fragrance_info = soup.find('div', attrs = {'class': 'css-1vwy1pm'}).strings\n",
    "    except:\n",
    "        return None\n",
    "    return list(fragrance_info)\n",
    "\n",
    "def get_rating(soup):\n",
    "    try:\n",
    "        rating_table = soup.find('table', attrs = {'class': 'css-960eb6'})\n",
    "        ratings = [list(r.strings) for r in rating_table]\n",
    "    except:\n",
    "        return None\n",
    "    return ratings\n",
    "\n",
    "\n",
    "def get_image_url(soup):\n",
    "    try:\n",
    "        image_url = soup.find('image')['xlink:href']\n",
    "    except:\n",
    "        return None\n",
    "    return image_url\n",
    "    \n",
    "\n",
    "\n",
    "def get_all_details(url):\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(url)\n",
    "    time.sleep(.5)\n",
    "    close_popup(browser)\n",
    "    html = auto_pagedowns(browser, no_of_pagedowns=6)\n",
    "    time.sleep(.5)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    \n",
    "    details_dict = {'brand_info':get_brand_perfume(soup), 'item_no_or_size':get_item_no(soup),\n",
    "                    'ratings': get_rating(soup), 'feedback': get_user_feedback(soup), \n",
    "                    'price': get_price(soup), 'oz_at_price': get_oz(soup), 'options': get_options(soup),\n",
    "                    'fragrance_info': get_fragrance_info(soup), 'image_url': get_image_url(soup), 'url': url\n",
    "        }\n",
    "    \n",
    "    return details_dict\n",
    "\n",
    "\n",
    "\n",
    "#sample_dict = get_all_details('https://www.sephora.com/product/replica-by-fireplace-P404758?icid2=products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dict_csv(urls, filename, dict_fields):\n",
    "    with open(filename, \"a\") as f:\n",
    "        writer = csv.DictWriter(f, dict_fields, delimiter = \",\")\n",
    "        writer.writeheader()\n",
    "        for url in urls:\n",
    "            product_dict = get_all_details(url)\n",
    "            writer.writerow(product_dict)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "perfume_proj",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
